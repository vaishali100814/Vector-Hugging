{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine learning"
      ],
      "metadata": {
        "id": "lhrv810MSHEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "  - A parameter is a numerical value that defines a model's behavior. In statistics, it's a measurable factor like mean or standard deviation. In machine learning, it refers to internal values (like weights in neural networks) that the model learns during training.\n",
        "2. What is correlation? What does negative correlation means?\n",
        "  - Correlation measures the relationship between two variables. It shows how one variable changes in response to another. A correlation coefficient (between -1 and 1) indicates the strength and direction of this relationship. Negative correlation means that as one variable increases, the other decreases. For example, if temperature goes up and sales of heaters go down, they have a negative correlation. The correlation coefficient is between 0 and -1.   \n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine Learning is a field where computers learn patterns from data without being explicitly programmed. The main components are: data, model, algorithm, loss function, and optimization method. These work together to make predictions or decisions.\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - The loss value shows how far the model's predictions are from actual results. A lower loss means better model performance. It helps in optimizing the model during training by guiding updates to the parameters.\n",
        "5. What are continuous and categorical variables?\n",
        "  - Continuous variables can take any numeric value within a range (e.g., height, weight). Categorical variables represent categories or labels (e.g., gender, color), and they may be nominal (no order) or ordinal (ordered).\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - One-hot encoding, ordinal encoding, and embedding are some of the most popular methods for handling categorical data in machine learning. Each of these methods has its own strengths and weaknesses, and the best approach will depend on the specific problem and dataset.\n",
        "7. What do you mean by training and testing a dataset?\n",
        "  - Training a dataset means using data to help the model learn patterns. Testing a dataset involves checking the model’s performance on unseen data to evaluate its accuracy and generalization ability.\n",
        "8. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in Scikit-learn that offers tools for scaling, encoding, and transforming data. It helps prepare data for machine learning by standardizing features and converting categorical variables into numerical ones.\n",
        "9. What is a Test set?\n",
        "  - A test set is a portion of data reserved for evaluating a trained machine learning model. It helps check how well the model performs on new, unseen data, ensuring it generalizes well.\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "  - We use train_test_split from sklearn.model_selection to split data. Typically, 70–80% goes to training and 20–30% to testing. First, understand the problem and gather data. Then clean and preprocess the data. Next, select a suitable model, train it, and evaluate using metrics. Tune parameters, retrain if needed, and finally deploy or interpret results\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "  - Exploratory Data Analysis (EDA) helps understand data patterns, detect anomalies, and assess relationships between variables. It reveals data quality issues like missing values or outliers and ensures proper preprocessing before model training, leading to better performance.\n",
        "12. What is correlation?\n",
        "  - Correlation measures the strength and direction of a relationship between two variables. It’s represented by a coefficient ranging from -1 (perfect negative) to +1 (perfect positive), with 0 indicating no linear relationship.\n",
        "13. What does negative correlation mean?\n",
        "  - Negative correlation means that as one variable increases, the other decreases. For example, as speed increases, travel time usually decreases. The correlation coefficient lies between 0 and -1.\n",
        "14. How can you find correlation between variables in Python?\n",
        "  - You can use the .corr() function in pandas, In Python, the correlation between variables can be found using various libraries and functions, depending on the type of correlation desired and the structure of the data.  For Two Variables (Arrays/Series): NumPy's corrcoef(): This function calculates the Pearson correlation coefficient between two one-dimensional arrays or lists. It returns a correlation matrix.\n",
        "15. What is causation? Explain difference between correlation and causation with an example?\n",
        "  - Causation means one variable directly affects another. Correlation shows association but not cause. Example: Ice cream sales and drowning rates are correlated (both rise in summer), but one doesn't cause the other. The hidden cause is hot weather.\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer updates model parameters to minimize the loss. Common types:SGD: Basic gradient descent.Adam: Combines momentum & RMSProp, adapts learning rate.RMSProp: Adjusts learning rate for each parameter. Example using Adam in TensorFlow:\n",
        "17. What is sklearn.linear_model?\n",
        "  - sklearn.linear_model is a Scikit-learn module that provides linear models like Linear Regression, Logistic Regression, and Ridge. These are used for regression and classification tasks depending on the problem type.\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "  - model.fit() trains the model on data. Required arguments:X_train: input featuresy_train: target variable Example: weights and biases in a neural network) to minimize a defined loss function.\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "  - Purpose : model. predict() is used to generate predictions from the    trained model based on new input data. It does not require true labels and does not compute any metrics.model.predict() makes predictions using the trained model. Argument:X_test: input features to predict on Example: classification models might output probabilities, while regression models might output continuous values.\n",
        "20. What are continuous and categorical variables?\n",
        "  - Continuous variables: Numeric values that can be measured (e.g., height, income).Categorical variables: Values that represent categories or labels (e.g., gender, color). They must be handled differently during data preprocessing.\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling transforms features to a similar scale, preventing models from favoring features with larger values. It improves performance in algorithms like KNN, SVM, or Gradient Descent-based models where distance or magnitude matters.\n",
        "22. How do we perform scaling in Python?\n",
        "  - Scaling data in Python, particularly for machine learning, typically involves transforming numerical features to a similar range or distribution. This is crucial for many algorithms that are sensitive to the scale of input features. The sklearn.preprocessing module provides various scalers for this purpose.\n",
        "23. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in Scikit-learn offering functions for scaling, normalization, encoding, and transformation of data. It prepares raw data for modeling by converting it into a form suitable for algorithms.\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "  - To split data into training and testing sets for model fitting in Python, the train_test_split function from the sklearn.model_selection module is commonly used. This function divides the data into two sets: one for training the model and the other for evaluating its performance on unseen data.\n",
        "25. Explain data encoding?\n",
        "  - Data encoding converts categorical values into numeric formats for machine learning. Common methods:\n",
        "\n",
        "Label Encoding: Assigns each category an integer.\n",
        "\n",
        "One-Hot Encoding: Creates binary columns for each category. Encoding ensures algorithms can process non-numeric data.                \n"
      ],
      "metadata": {
        "id": "KRfGYFXOSM_h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "25cIIShBSKkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}